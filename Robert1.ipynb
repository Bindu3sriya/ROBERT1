{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4f424d-e5a0-429a-b2b1-36476af26e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Obtaining dependency information for seaborn from https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl.metadata\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\python312\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Obtaining dependency information for pandas>=1.2 from https://files.pythonhosted.org/packages/71/00/6beaeeba7f075d15ea167a5caa039b861e58ff2f58a5b659abb9b544c8f6/pandas-2.2.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached pandas-2.2.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Obtaining dependency information for matplotlib!=3.6.1,>=3.4 from https://files.pythonhosted.org/packages/50/ce/a6bc93f7a44dd1fd23698698e369e141f4f24e7098d0a5937808afee3f5e/matplotlib-3.8.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/8e/ae/a6353db548bff1a592b85ae6bb80275f0a51dc25a0410d059e5b33183e36/contourpy-1.2.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading contourpy-1.2.0-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/28/27/42f5cac9f5ee15ab65b3fd939e37a115a0a5e367fcabde5b901599daa85a/fonttools-4.49.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading fonttools-4.49.0-cp312-cp312-win_amd64.whl.metadata (162 kB)\n",
      "     ---------------------------------------- 0.0/162.3 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/162.3 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 61.4/162.3 kB 825.8 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 143.4/162.3 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 162.3/162.3 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/63/50/2746566bdf4a6a842d117367d05c90cfb87ac04e9e2845aa1fa21f071362/kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/51/07/7e9266a59bb267b56c1f432f6416653b9a78dda771c57740d064a8aa2a44/pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/9d/ea/6d76df31432a0e6fdf81681a895f009a4bb47b3c39036db3e1b528191d52/pyparsing-3.1.2-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for python-dateutil>=2.7 from https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for six>=1.5 from https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 122.9/294.9 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 276.5/294.9 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.9/294.9 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.6 MB 15.4 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.6/7.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/7.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/7.6 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.5/7.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.6/7.6 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/7.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.7/7.6 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.3/7.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.8/7.6 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.6 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.9/7.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.1-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.5 MB 16.8 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.1/11.5 MB 13.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 12.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.2/11.5 MB 12.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/11.5 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.3/11.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.5 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.4/11.5 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.9/11.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.4/11.5 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/11.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.5/11.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.5 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.2/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.8/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.3/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.9/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.0-cp312-cp312-win_amd64.whl (187 kB)\n",
      "   ---------------------------------------- 0.0/187.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 187.7/187.7 kB 11.1 MB/s eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.0/56.0 kB ? eta 0:00:00\n",
      "Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.6 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.6 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.6 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.2/103.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 229.9/229.9 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 505.5/505.5 kB 10.8 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.4/345.4 kB 10.8 MB/s eta 0:00:00\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, six, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, python-dateutil, pandas, matplotlib, seaborn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Python312\\\\share'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2abece2d-2e59-43e5-80aa-1933d7094fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.2.1)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/a1/e3/5fd1c7d1836141b0bd253502be910c73d84a34ced27a289ea4ca4975ef3b/torchvision-0.17.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.17.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/77/f7/6ddef43a933637ad0d80432420c6928882ca8bf19361e20bf8f7417228ba/torchaudio-2.2.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading torchaudio-2.2.1-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torchvision-0.17.1-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Downloading torchaudio-2.2.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.4 MB 393.8 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/2.4 MB 655.4 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.2/2.4 MB 919.0 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.4 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.2.1 torchvision-0.17.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3caabd3d-43f2-4d43-8459-7cf741249c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from transformers import logging\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7eca89a-08dd-49ad-b3a4-33581497abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('JRA3500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f9d93bf-52a1-425d-ae8e-caa39c5086b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "df.dropna(subset=['title', 'description', 'component'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d50a943-9c62-4d06-b58f-4ee2ffb1f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Delete new line tags and other known tags\n",
    "    text = re.sub(r'[\\n\\r\\t]', ' ', text)\n",
    "    \n",
    "    # Delete URL\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Delete stack trace\n",
    "    text = re.sub(r'Stack trace:.*(\\n.*){1,10}', '', text)\n",
    "    \n",
    "    # Delete hex code\n",
    "    text = re.sub(r'0x[0-9a-fA-F]+', '', text)\n",
    "    \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "070ff875-7f01-434e-b0af-8448e756574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the dataframe\n",
    "df['title'] = df['title'].apply(preprocess_text)\n",
    "df['description'] = df['description'].apply(preprocess_text)\n",
    "# Combine the title and description into a single text field\n",
    "df['text'] = df['title'] + \" \" + df['description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6c4321c-aa8b-4d50-b5c3-a278b61b0344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component\n",
      "Issue - Fields                                                 250\n",
      "Documentation - All                                            238\n",
      "Dashboards & Reports - Gadgets                                 225\n",
      "Events & Notifications - Email                                 172\n",
      "User Management - Others                                       168\n",
      "                                                              ... \n",
      "JQL ,System Administration - Jelly                               1\n",
      "Ecosystem - REST API,Issue - Comments                            1\n",
      "Filtering & Indexing ,Project Administration - Workflows         1\n",
      "Administration ,Issue Navigation & Search - Bulk Operations      1\n",
      "Issue - Fields,Issue Navigation & Search - Export                1\n",
      "Name: count, Length: 303, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the count of each component\n",
    "component_counts = df['component'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(component_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3983cdc2-6d1e-495f-aaa1-1e3ce21a311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_counts = df['component'].value_counts()\n",
    "df = df[~df['component'].isin(component_counts[component_counts < 100].index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95c05e8c-fff3-4683-84d4-8130e45e6c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component\n",
      "Issue - Fields                              250\n",
      "Documentation - All                         238\n",
      "Dashboards & Reports - Gadgets              225\n",
      "Events & Notifications - Email              172\n",
      "User Management - Others                    168\n",
      "Administration                              154\n",
      "JQL                                         146\n",
      "Plugins                                     145\n",
      "Project Administration - Workflows          124\n",
      "Infrastructure & Services - Installation    123\n",
      "Issue navigator                             118\n",
      "Issue - Attachments                         102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the count of each component\n",
    "component_counts = df['component'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(component_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25c955e7-54c0-4e31-b78e-0373917367a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Dataset Class\n",
    "class ComponentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        # Encode the text into tensors and return a dictionary\n",
    "        data = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': data['input_ids'].flatten(),\n",
    "            'attention_mask': data['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d72b8bed-8ca2-49a6-8274-1668d1c202f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels into unique integers\n",
    "label_unique = df['component'].unique()\n",
    "label_dict = {label: idx for idx, label in enumerate(label_unique)}\n",
    "df['label'] = df['component'].map(label_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2377f0a7-79c8-436d-8a0b-0d93a0fd65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_test, 'data_type'] = 'test'\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6dcc5bcf-2ad0-4002-8f5a-7f7eff0083ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "train_dataset = ComponentDataset(\n",
    "    texts=df[df.data_type=='train'].text.values,\n",
    "    labels=df[df.data_type=='train'].label.values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "test_dataset = ComponentDataset(\n",
    "    texts=df[df.data_type=='test'].text.values,\n",
    "    labels=df[df.data_type=='test'].label.values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4aba10a3-757a-4f83-beab-3e35392dfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4cfa133f-a200-427a-a4a2-383c40917b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# Load the RoBERTa model for sequence classification\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels=len(label_dict), # The number of output labels\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a32f294c-3345-4d63-8499-6a355dc1694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, weight_decay=5e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "423390f0-3194-45b0-b9cb-d023c673b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_dataloader) * epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "838621cf-cbaf-4c9d-9ea1-825a7bb67d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3c4e6f8-fe56-42aa-9aee-397c15030aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "# Define training parameters\n",
    "epochs = 3\n",
    "max_grad_norm = 1.0\n",
    "early_stopping_counter = 0\n",
    "early_stopping_patience = 3\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4bce4d64-6ea1-47eb-80ae-3bdcb7c41850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Training loss: 2.4743\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | Training loss: 2.3450\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | Training loss: 2.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    progress_bar = tqdm(train_dataloader, desc='Batch', leave=False, total=len(train_dataloader))\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update the progress bar with the loss information\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "        \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    train_loss = loss_train_total / len(train_dataloader)\n",
    "    \n",
    "    # Closing the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} | Training loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7dc8c085-e7b4-4b1d-868c-82d1f1cc0b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "                User Management - Others       0.57      0.80      0.67        25\n",
      "Infrastructure & Services - Installation       0.00      0.00      0.00        18\n",
      "          Events & Notifications - Email       0.48      0.62      0.54        26\n",
      "                        Issue navigator        0.00      0.00      0.00        18\n",
      "                     Issue - Attachments       0.00      0.00      0.00        15\n",
      "      Project Administration - Workflows       0.90      0.47      0.62        19\n",
      "                     Documentation - All       0.32      0.69      0.43        36\n",
      "                                Plugins        0.57      0.18      0.28        22\n",
      "                         Administration        0.50      0.04      0.08        23\n",
      "          Dashboards & Reports - Gadgets       0.69      0.59      0.63        34\n",
      "                                    JQL        0.73      0.36      0.48        22\n",
      "                          Issue - Fields       0.32      0.76      0.45        37\n",
      "\n",
      "                                accuracy                           0.44       295\n",
      "                               macro avg       0.42      0.38      0.35       295\n",
      "                            weighted avg       0.44      0.44      0.39       295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "            true_labels.extend(batch['labels'].tolist())\n",
    "    \n",
    "    return true_labels, predictions\n",
    "\n",
    "# Evaluate the model\n",
    "true_labels, predictions = evaluate(model, test_dataloader)\n",
    "\n",
    "# Compute the performance metrics\n",
    "report = classification_report(true_labels, predictions, target_names=label_dict.keys())\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f58f31f-4f32-452a-b698-2849ac7c308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_path = \"roberta_component_classification\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "# To load the model and tokenizer later\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "loaded_tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "loaded_model = RobertaForSequenceClassification.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7af8cb5e-637f-470c-87df-8eb201a0cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.41%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb2263-c547-47b6-9ac6-5b47f19e734f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
